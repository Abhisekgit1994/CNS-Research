{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8616d69",
   "metadata": {},
   "source": [
    "# Deep Learning for cellular image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25942ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Laptop GPU'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d314a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0633dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\abhis/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66397860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f7dc2",
   "metadata": {},
   "source": [
    "# Transfer learning using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b4624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9265f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "# stride controls the stride for the cross-correlation, a single number or a tuple.\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b837f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d7e178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed0184",
   "metadata": {},
   "source": [
    "# Testing on CNS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856ebafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eab1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'E:/Abhi/Alienware/INDIANA UNIVERSITY/CNS Research test data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9ca0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = {x: datasets.ImageFolder(os.path.join(img_dir, x), data_transforms[x]) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea0a4a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 1200\n",
       "     Root location: E:/Abhi/Alienware/INDIANA UNIVERSITY/CNS Research test data\\train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomResizedCrop(size=(299, 299), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            ),\n",
       " 'test': Dataset ImageFolder\n",
       "     Number of datapoints: 600\n",
       "     Root location: E:/Abhi/Alienware/INDIANA UNIVERSITY/CNS Research test data\\test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomResizedCrop(size=(299, 299), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            )}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8067510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(img_data[x], batch_size =4, shuffle= True, num_workers =4) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87842026",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizes = {x: len(img_data[x]) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb6d88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = img_data['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e6370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colon',\n",
       " 'endometrium_1',\n",
       " 'endometrium_2',\n",
       " 'kidney',\n",
       " 'liver',\n",
       " 'lung',\n",
       " 'lymph_node',\n",
       " 'pancreas',\n",
       " 'skin_1',\n",
       " 'skin_2',\n",
       " 'small_intestine',\n",
       " 'spleen']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e313fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
    "        print(\"-\"*10)\n",
    "        \n",
    "        # each epoch has a training and validation phase\n",
    "        for phase in ['train','test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                \n",
    "                # zero the optimizer gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs,1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "#                     loss2 = criterion(aux_outs, labels)\n",
    "#                     loss = loss1+0.4*loss2\n",
    "                    \n",
    "                    # backward+optimize\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                \n",
    "                running_loss+= loss.item()*inputs.size(0)\n",
    "                running_corrects+= torch.sum(preds==labels.data)\n",
    "                \n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "                    \n",
    "            epoch_loss = running_loss/img_sizes[phase]\n",
    "            epoch_acc = running_corrects.double()/img_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase=='test' and epoch_acc>best_acc:\n",
    "                best_acc=epoch_acc\n",
    "                best_model_wts=copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        \n",
    "    print('Best test Acc:{:2f}'.format(best_acc))\n",
    "        \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e14c87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd306f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\abhis/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained= True)\n",
    "model.aux_logits=False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "# Here the size of each output sample is set to 12.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, 12)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14428be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 2.4457 Acc: 0.1200\n",
      "test Loss: 2.2820 Acc: 0.3667\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 2.2374 Acc: 0.2908\n",
      "test Loss: 2.0439 Acc: 0.5133\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 2.0366 Acc: 0.3758\n",
      "test Loss: 1.7918 Acc: 0.5467\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.7969 Acc: 0.4658\n",
      "test Loss: 1.5094 Acc: 0.6150\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.5935 Acc: 0.5125\n",
      "test Loss: 1.3268 Acc: 0.6117\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.4729 Acc: 0.5275\n",
      "test Loss: 1.1452 Acc: 0.6817\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.3596 Acc: 0.5750\n",
      "test Loss: 0.9908 Acc: 0.7000\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.2735 Acc: 0.6058\n",
      "test Loss: 0.9187 Acc: 0.7283\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.2420 Acc: 0.6092\n",
      "test Loss: 0.9656 Acc: 0.7117\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.2454 Acc: 0.6067\n",
      "test Loss: 0.9314 Acc: 0.7267\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.2656 Acc: 0.5933\n",
      "test Loss: 0.9209 Acc: 0.7417\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.2066 Acc: 0.6292\n",
      "test Loss: 0.8992 Acc: 0.7500\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.2341 Acc: 0.6200\n",
      "test Loss: 0.8936 Acc: 0.7333\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.1886 Acc: 0.6300\n",
      "test Loss: 0.8909 Acc: 0.7300\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.1867 Acc: 0.6283\n",
      "test Loss: 0.8919 Acc: 0.7383\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.2383 Acc: 0.6117\n",
      "test Loss: 0.8856 Acc: 0.7550\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.2100 Acc: 0.6208\n",
      "test Loss: 0.9034 Acc: 0.7283\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.1759 Acc: 0.6425\n",
      "test Loss: 0.8597 Acc: 0.7367\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.2103 Acc: 0.6242\n",
      "test Loss: 0.8797 Acc: 0.7500\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.2167 Acc: 0.6108\n",
      "test Loss: 0.8745 Acc: 0.7533\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.2220 Acc: 0.6350\n",
      "test Loss: 0.8792 Acc: 0.7283\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.1965 Acc: 0.6267\n",
      "test Loss: 0.8940 Acc: 0.7233\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.1706 Acc: 0.6233\n",
      "test Loss: 0.9297 Acc: 0.7167\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.2176 Acc: 0.6242\n",
      "test Loss: 0.8677 Acc: 0.7500\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.2040 Acc: 0.6217\n",
      "test Loss: 0.8720 Acc: 0.7367\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.1858 Acc: 0.6400\n",
      "test Loss: 0.9276 Acc: 0.7083\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.2179 Acc: 0.6100\n",
      "test Loss: 0.8713 Acc: 0.7650\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.2637 Acc: 0.6008\n",
      "test Loss: 0.8944 Acc: 0.7350\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.2018 Acc: 0.6225\n",
      "test Loss: 0.8505 Acc: 0.7583\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.2257 Acc: 0.6183\n",
      "test Loss: 0.8810 Acc: 0.7300\n",
      "Best test Acc:0.765000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e063f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77.50 % test accuracy achieved on test dataset #run1 with inception_v3 pretrained\n",
    "# 76.50 % test accuracy achieved on test dataset #run2 with inception_v3 pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c1df26",
   "metadata": {},
   "source": [
    "# CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe164d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25367296",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'E:/Abhi/Alienware/INDIANA UNIVERSITY/CNS Research test data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbe00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = {x: datasets.ImageFolder(os.path.join(img_dir, x), data_transforms[x]) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dc9c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(img_data[x], batch_size =4, shuffle= True, num_workers =4) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edce415",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizes = {x: len(img_data[x]) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99fa46de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 1200, 'test': 600}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5227ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382dcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb55ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c49f64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8894528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "199d3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st trial\n",
    "class myCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 16, 5)\n",
    "        self.fc1 = nn.Linear(80656,512 )\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, 12)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f452442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd trial\n",
    "class myCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3= nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc1 = nn.Linear(57600, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc3 = nn.Linear(512, 12)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec6a7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0803bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed8ae6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3eda14c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.4852 Acc: 0.0725\n",
      "test Loss: 2.4821 Acc: 0.0850\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 2.4794 Acc: 0.0792\n",
      "test Loss: 2.4761 Acc: 0.0950\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 2.4720 Acc: 0.0867\n",
      "test Loss: 2.4673 Acc: 0.1033\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 2.4614 Acc: 0.0958\n",
      "test Loss: 2.4571 Acc: 0.0933\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 2.4452 Acc: 0.1125\n",
      "test Loss: 2.4417 Acc: 0.1017\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 2.4244 Acc: 0.1142\n",
      "test Loss: 2.4198 Acc: 0.1117\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 2.3907 Acc: 0.1500\n",
      "test Loss: 2.3820 Acc: 0.1400\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 2.3573 Acc: 0.1742\n",
      "test Loss: 2.3769 Acc: 0.1533\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 2.3489 Acc: 0.1850\n",
      "test Loss: 2.3676 Acc: 0.1467\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 2.3423 Acc: 0.1967\n",
      "test Loss: 2.3554 Acc: 0.1650\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 2.3334 Acc: 0.2050\n",
      "test Loss: 2.3549 Acc: 0.1683\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 2.3264 Acc: 0.2008\n",
      "test Loss: 2.3472 Acc: 0.1733\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 2.3183 Acc: 0.2058\n",
      "test Loss: 2.3353 Acc: 0.1817\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 2.3067 Acc: 0.2050\n",
      "test Loss: 2.3321 Acc: 0.1833\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 2.3002 Acc: 0.2083\n",
      "test Loss: 2.3280 Acc: 0.1817\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 2.3007 Acc: 0.2083\n",
      "test Loss: 2.3300 Acc: 0.1817\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 2.3037 Acc: 0.2058\n",
      "test Loss: 2.3194 Acc: 0.1750\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 2.2990 Acc: 0.2225\n",
      "test Loss: 2.3233 Acc: 0.1783\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 2.3001 Acc: 0.2125\n",
      "test Loss: 2.3228 Acc: 0.1850\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 2.2990 Acc: 0.2150\n",
      "test Loss: 2.3226 Acc: 0.1717\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 2.2957 Acc: 0.2208\n",
      "test Loss: 2.3220 Acc: 0.1717\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 2.2941 Acc: 0.2217\n",
      "test Loss: 2.3167 Acc: 0.1867\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 2.2946 Acc: 0.2192\n",
      "test Loss: 2.3198 Acc: 0.1750\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 2.2973 Acc: 0.2142\n",
      "test Loss: 2.3233 Acc: 0.1817\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 2.3006 Acc: 0.2183\n",
      "test Loss: 2.3260 Acc: 0.1867\n",
      "Best test Acc:0.186667\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st trial 1st run gave 30% test accuracy\n",
    "# it gave 19% accuracy in the 2nd run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aa4382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.4842 Acc: 0.0858\n",
      "test Loss: 2.4805 Acc: 0.1133\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 2.4795 Acc: 0.1000\n",
      "test Loss: 2.4758 Acc: 0.1017\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 2.4728 Acc: 0.1117\n",
      "test Loss: 2.4668 Acc: 0.1233\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 2.4619 Acc: 0.1225\n",
      "test Loss: 2.4518 Acc: 0.1517\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 2.4436 Acc: 0.1450\n",
      "test Loss: 2.4211 Acc: 0.1567\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 2.3973 Acc: 0.1683\n",
      "test Loss: 2.3632 Acc: 0.1700\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 2.3207 Acc: 0.1867\n",
      "test Loss: 2.2913 Acc: 0.1917\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 2.2554 Acc: 0.1992\n",
      "test Loss: 2.2628 Acc: 0.2050\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 2.2161 Acc: 0.2075\n",
      "test Loss: 2.2476 Acc: 0.1933\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 2.2022 Acc: 0.2175\n",
      "test Loss: 2.2491 Acc: 0.1967\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 2.2126 Acc: 0.2150\n",
      "test Loss: 2.2233 Acc: 0.2033\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 2.1950 Acc: 0.2083\n",
      "test Loss: 2.2199 Acc: 0.2100\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 2.1868 Acc: 0.2267\n",
      "test Loss: 2.2095 Acc: 0.1950\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 2.1771 Acc: 0.2292\n",
      "test Loss: 2.2166 Acc: 0.2017\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 2.1800 Acc: 0.2283\n",
      "test Loss: 2.2263 Acc: 0.2133\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 2.1602 Acc: 0.2358\n",
      "test Loss: 2.2019 Acc: 0.2000\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 2.1656 Acc: 0.2242\n",
      "test Loss: 2.2079 Acc: 0.2250\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 2.1504 Acc: 0.2342\n",
      "test Loss: 2.1934 Acc: 0.2183\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 2.1667 Acc: 0.2342\n",
      "test Loss: 2.2166 Acc: 0.2067\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 2.1558 Acc: 0.2408\n",
      "test Loss: 2.2088 Acc: 0.2133\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 2.1616 Acc: 0.2292\n",
      "test Loss: 2.1987 Acc: 0.2000\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 2.1510 Acc: 0.2367\n",
      "test Loss: 2.1941 Acc: 0.2033\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 2.1557 Acc: 0.2458\n",
      "test Loss: 2.2019 Acc: 0.2050\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 2.1581 Acc: 0.2525\n",
      "test Loss: 2.2056 Acc: 0.1950\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 2.1610 Acc: 0.2425\n",
      "test Loss: 2.2036 Acc: 0.2017\n",
      "Best test Acc:0.225000\n"
     ]
    }
   ],
   "source": [
    "# MODEL WITH RESIZED 499 #2nd trial\n",
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8370b09",
   "metadata": {},
   "source": [
    "## Q.Explain why some images might have been classified incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53794d2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\">\n",
    "    <p>-->first the model relates the test data with training data mathematically.so it can happen that the mathematical correlation is absolutely correct all the time.</p><br>\n",
    "    <p>-->As the pixels for the images are very large when we crop the images for preprocessing it might happen the image can loose necessary informations.</p><br>\n",
    "    <p>-->The number of layers not built in as exact solution. Even if we tuned the inception_v3 dataset we could not achieve above 90% accuracy as model was unable to generalize even if the inception_v3 as more than 100 layers.</p><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1b1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
